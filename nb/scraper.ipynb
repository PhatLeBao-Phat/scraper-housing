{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSoup sample \n",
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")   # Return bs4.BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheatsheet\n",
    "# ----------\n",
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "# ----------\n",
    "\n",
    "# Return bs4.BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Find HTML Element -> Return bs4.element.Tag\n",
    "results = soup.find(\n",
    "    name=\"input\",\n",
    "    id=\"ResultsContainer\",\n",
    ") \n",
    "\n",
    "# print(soup.prettify())\n",
    "\n",
    "# Find sub elements in element\n",
    "job_cards = soup.find_all(\"div\", class_=\"card-content\")\n",
    "\n",
    "# Pass a function to a bs4 method \n",
    "python_jobs = results.find_all(\n",
    "    \"h2\", string=lambda text: \"python\" in text.lower()\n",
    ");\n",
    "\n",
    "# Fetch links in the job boards \n",
    "# If you used .text then it will leave only visable part, so only text is left \n",
    "# So the link you want in href is stripped as well. Do the following instead\n",
    "for job_card in job_cards:\n",
    "    link_url = job_card.find_all(\"a\")[1][\"href\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sample with HousingTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs4 is a library to navigate documents \n",
    "- requests is a library for well, requesting but mostly to work with http session \n",
    "- MechanicalSoup is a Python library for automating interaction with websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "from selenium import webdriver\n",
    "import mechanicalsoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pathlib\n",
    "import importlib\n",
    "import requests \n",
    "\n",
    "sys.path.append(str(pathlib.Path.cwd().parent))\n",
    "\n",
    "import scraper\n",
    "scraper = importlib.reload(scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get browser object \n",
    "url = \"https://www.housingtarget.com/netherlands\"\n",
    "browser = mechanicalsoup.Browser()\n",
    "page = browser.get(url)\n",
    "\n",
    "# Get html \n",
    "html = page.soup\n",
    "\n",
    "form = html.select(\"form\")[0]\n",
    "form.find(\"input\", {\"name\": \"LeftMenu_ZipCodes\"})[\"value\"] = \"Utretch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mechanicalsoup\n",
    "\n",
    "# Create a browser object\n",
    "browser = mechanicalsoup.StatefulBrowser()\n",
    "\n",
    "# Open the webpage\n",
    "browser.open(\"https://www.housingtarget.com/netherlands\")\n",
    "\n",
    "browser.select_form()\n",
    "\n",
    "form = browser.get_current_form()\n",
    "form[\"LeftMenu_LPEstateTypes\"] = [\"2\", \"3\", \"9\", \"20\"]\n",
    "form[\"LeftMenu_ZipCodes\"] = \"1319\"\n",
    "\n",
    "response = browser.submit_selected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome options\n",
    "chrome_option = Options()\n",
    "chrome_option.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_option)\n",
    "\n",
    "# Open the page after the form is submitted\n",
    "driver.get(\n",
    "    # 'https://www.housingtarget.com/netherlands/housing-rentals?' + \n",
    "    # 'zip_codes=1039;1319&estate_types=2;3;9;20&area_to=69&max_rent=2000'\n",
    "    'https://www.housingtarget.com/netherlands/housing-rentals/amsterdam'\n",
    ")\n",
    "\n",
    "ul_element = driver.find_element(By.CLASS_NAME, 'table-ads')\n",
    "li_elements = ul_element.find_elements(By.TAG_NAME, 'li')\n",
    "listings = [li for li in li_elements if li.get_attribute(\"class\") == \"\" and li.find_elements(By.TAG_NAME, \"div\")]\n",
    "\n",
    "html = BeautifulSoup(driver.find_element(By.CLASS_NAME, \"pager\").get_attribute(\"outerHTML\"), \"html.parser\")\n",
    "urls = [e[\"href\"] for e in html.find_all(\"a\")] \n",
    "parsed_listings = [scraper.parse_listing_html(li) for li in listings]\n",
    "r = pd.DataFrame(parsed_listings, columns = [\"link\", \"rent\", \"size\", \"property_type\", \"location\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam\n",
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam/pageindex2\n",
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam/pageindex3\n",
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam/pageindex4\n"
     ]
    }
   ],
   "source": [
    "scraper.listing_spider(\"https://www.housingtarget.com/netherlands/housing-rentals/amsterdam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get details of listings\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.housingtarget.com/rooms/utrecht-overvecht/12485098'\n",
    "\n",
    "def get_listing_attr(url):\n",
    "    try:\n",
    "        page = requests.get(url, timeout=10)\n",
    "        page.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    html = soup.find(\"div\", class_=\"top-info-mobile\")\n",
    "    if not html:\n",
    "        return None, None, None, None    \n",
    "    \n",
    "    title = html.findChild(\"h1\").text\n",
    "    street = html.findChild(\"strong\").text\n",
    "    description = soup.find_all(\"div\", {\"class\" : \"desc\"})[0].text\n",
    "    seo = soup.find_all(\"div\", {\"class\" : \"seo\"})[0].text\n",
    "\n",
    "    return title, street, description, seo\n",
    "\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Place based on query \n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
