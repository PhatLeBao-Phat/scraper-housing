{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSoup sample \n",
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")   # Return bs4.BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheatsheet\n",
    "# ----------\n",
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "# ----------\n",
    "\n",
    "# Return bs4.BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Find HTML Element -> Return bs4.element.Tag\n",
    "results = soup.find(\n",
    "    name=\"input\",\n",
    "    id=\"ResultsContainer\",\n",
    ") \n",
    "\n",
    "# print(soup.prettify())\n",
    "\n",
    "# Find sub elements in element\n",
    "job_cards = soup.find_all(\"div\", class_=\"card-content\")\n",
    "\n",
    "# Pass a function to a bs4 method \n",
    "python_jobs = results.find_all(\n",
    "    \"h2\", string=lambda text: \"python\" in text.lower()\n",
    ");\n",
    "\n",
    "# Fetch links in the job boards \n",
    "# If you used .text then it will leave only visable part, so only text is left \n",
    "# So the link you want in href is stripped as well. Do the following instead\n",
    "for job_card in job_cards:\n",
    "    link_url = job_card.find_all(\"a\")[1][\"href\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sample with Glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bs4 is a library to navigate documents \n",
    "- requests is a library for well, requesting but mostly to work with http session \n",
    "- MechanicalSoup is a Python library for automating interaction with websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import mechanicalsoup\n",
    "from pprint import pprint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from typing import Tuple\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Parse the listings\n",
    "def _search_str_property(listing):\n",
    "    size_match = re.search(r'(\\d+\\s*m2)', listing)\n",
    "    size = size_match.group(1) if size_match else None\n",
    "\n",
    "    # 2. Find the property type (e.g., apartment, house, room)\n",
    "    type_match = re.search(r'\\b(apartment|house|room)\\b', listing, re.IGNORECASE)\n",
    "    property_type = type_match.group(1) if type_match else None\n",
    "\n",
    "    # 3. Find the location (everything after \"in\")\n",
    "    location_match = re.search(r'(?<=\\bin\\s)(.*)', listing)\n",
    "    location = location_match.group(1).strip() if location_match else None\n",
    "\n",
    "    return (size, property_type, location)\n",
    "\n",
    "def parse_listing_html(li_element : str) -> Tuple[str, int]:\n",
    "    bs4_html = BeautifulSoup(li_element.get_attribute(\"outerHTML\"), 'html.parser')\n",
    "    link = bs4_html.find(\"a\")[\"href\"]\n",
    "    rent = bs4_html.find(\"label\").parent.find(\"span\").text\n",
    "    size, property_type, location = _search_str_property(bs4_html.find(\"a\").text)\n",
    "\n",
    "    return link, rent, size, property_type, location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get browser object \n",
    "url = \"https://www.housingtarget.com/netherlands\"\n",
    "browser = mechanicalsoup.Browser()\n",
    "page = browser.get(url)\n",
    "\n",
    "# Get html \n",
    "html = page.soup\n",
    "\n",
    "form = html.select(\"form\")[0]\n",
    "form.find(\"input\", {\"name\": \"LeftMenu_ZipCodes\"})[\"value\"] = \"Utretch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mechanicalsoup\n",
    "\n",
    "# Create a browser object\n",
    "browser = mechanicalsoup.StatefulBrowser()\n",
    "\n",
    "# Open the webpage\n",
    "browser.open(\"https://www.housingtarget.com/netherlands\")\n",
    "\n",
    "browser.select_form()\n",
    "\n",
    "form = browser.get_current_form()\n",
    "form[\"LeftMenu_LPEstateTypes\"] = [\"2\", \"3\", \"9\", \"20\"]\n",
    "form[\"LeftMenu_ZipCodes\"] = \"1319\"\n",
    "\n",
    "response = browser.submit_selected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome options\n",
    "chrome_option = Options()\n",
    "chrome_option.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_option)\n",
    "\n",
    "# Open the page after the form is submitted\n",
    "driver.get(\n",
    "    # 'https://www.housingtarget.com/netherlands/housing-rentals?' + \n",
    "    # 'zip_codes=1039;1319&estate_types=2;3;9;20&area_to=69&max_rent=2000'\n",
    "    'https://www.housingtarget.com/netherlands/housing-rentals/amsterdam'\n",
    ")\n",
    "\n",
    "ul_element = driver.find_element(By.CLASS_NAME, 'table-ads')\n",
    "li_elements = ul_element.find_elements(By.TAG_NAME, 'li')\n",
    "listings = [li for li in li_elements if li.get_attribute(\"class\") == \"\" and li.find_elements(By.TAG_NAME, \"div\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = BeautifulSoup(driver.find_element(By.CLASS_NAME, \"pager\").get_attribute(\"outerHTML\"), \"html.parser\")\n",
    "urls = [e[\"href\"] for e in html.find_all(\"a\")] \n",
    "parsed_listings = [parse_listing_html(li) for li in listings]\n",
    "r = pd.DataFrame(parsed_listings, columns = [\"link\", \"rent\", \"size\", \"property_type\", \"location\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing_spider(root_url, base_url='https://www.housingtarget.com'):\n",
    "    visited = set()\n",
    "    final = []\n",
    "    def get_listings(url):\n",
    "        \"\"\"Get listings on an url\"\"\"\n",
    "        if url in visited:\n",
    "            return\n",
    "        print(f\"Visiting {url}\")\n",
    "        visited.add(url)\n",
    "        chrome_option = Options()\n",
    "        chrome_option.add_argument(\"--headless\")\n",
    "        driver = webdriver.Chrome(options=chrome_option)\n",
    "        driver.get(url)\n",
    "\n",
    "        ul_element = driver.find_element(By.CLASS_NAME, \"table-ads\")\n",
    "        li_elements = ul_element.find_elements(By.TAG_NAME, \"li\")\n",
    "        listings = [\n",
    "            li\n",
    "            for li in li_elements\n",
    "            if li.get_attribute(\"class\") == \"\" and li.find_elements(By.TAG_NAME, \"div\")\n",
    "        ]\n",
    "\n",
    "        parsed_listings = [parse_listing_html(li) for li in listings]\n",
    "        r = pd.DataFrame(\n",
    "            parsed_listings, columns=[\"link\", \"rent\", \"size\", \"property_type\", \"location\"]\n",
    "        )\n",
    "        final.append(r)\n",
    "\n",
    "        # Recursive \n",
    "        html = BeautifulSoup(driver.find_element(By.CLASS_NAME, \"pager\").get_attribute(\"outerHTML\"), \"html.parser\")\n",
    "        urls = [e[\"href\"] for e in html.find_all(\"a\") if  base_url + e[\"href\"] not in visited]\n",
    "        driver.quit()\n",
    "\n",
    "        for link in urls:\n",
    "            try:\n",
    "                get_listings('https://www.housingtarget.com' + link)\n",
    "            except Exception as e:\n",
    "                # raise ValueError(f\"{url}\")\n",
    "                print(f\"Can visit {link}\")\n",
    "        return r\n",
    "\n",
    "    get_listings(root_url)\n",
    "    result = pd.concat(final)\n",
    "    result.to_pickle(f\"outputs/{root_url}.pkl\")\n",
    "    return pd.concat(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam\n",
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam/pageindex2\n",
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam/pageindex3\n",
      "Visiting https://www.housingtarget.com/netherlands/housing-rentals/amsterdam/pageindex4\n"
     ]
    }
   ],
   "source": [
    "listing_spider(\"https://www.housingtarget.com/netherlands/housing-rentals/amsterdam\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
